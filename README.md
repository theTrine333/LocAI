# LocAI

LocAI is a user-friendly GUI for interacting with local language models running in Termux via Ollama. This app provides a sleek interface to communicate with LLMs, making it easier for users to send queries and view responses in an interactive, visually appealing format.

---

## Features

- **Local LLM Integration**: Seamless connection to language models hosted locally in Termux via Ollama.
- **Interactive UI**: A modern interface for querying and receiving responses from models.
- **Markdown Rendering**: Responses are displayed in rich Markdown for enhanced readability.
- **Customizable Themes**: Switch between light and dark modes to suit your preferences.
- **Real-Time Communication**: Supports HTTP and WebSocket connections for live interactions.

---

## Tech Stack

- **Frontend**: React Native with Expo
- **Backend**: Termux-hosted LLMs via Ollama
- **State Management**: Zustand
- **Styling**: React Native Paper
- **Markdown Rendering**: React Native Markdown Display
- **Networking**: Axios, Socket.IO

---

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/theTrine333/locai.git
   cd locai
   ```
